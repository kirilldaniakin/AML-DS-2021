{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TorchTut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UccsLrIDSuJF"
      },
      "source": [
        "## <center>PyTorch Tutorial<center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4He13qC7StI6"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "np.random.seed(73)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3dO6a6ce0E3"
      },
      "source": [
        "## <center> Linear Regression with Numpy<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB1XeGRfWzwL"
      },
      "source": [
        "### Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVKWjKdxTnx-"
      },
      "source": [
        "# Data Generation\n",
        "def generate_data(size = 100):\n",
        "\n",
        "  x = np.random.rand(size, 1)\n",
        "  y = 3 + 2.5 * x + .1 * np.random.randn(size, 1)\n",
        "\n",
        "  # Shuffles the indices\n",
        "  idx = np.arange(size)\n",
        "  np.random.shuffle(idx)\n",
        "\n",
        "  # split to train and validation 80:20\n",
        "  split = int(size * 0.8)\n",
        "  train_idx = idx[:split]\n",
        "  val_idx = idx[split:]\n",
        "\n",
        "  # Generate train and validation sets\n",
        "  x_train, y_train = x[train_idx], y[train_idx]\n",
        "  x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "  return x_train, y_train, x_val, y_val"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FN5dKNZGW6BA",
        "outputId": "d9da1ee8-f75c-4175-8ad1-3f8c5859e00c"
      },
      "source": [
        "x_train, y_train, x_val, y_val = generate_data()\n",
        "plt.scatter(x_train, y_train)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbCElEQVR4nO3df5BldXnn8c9nmhZ6jNJEOllsiMNWzCTBCQx0EVKddQUjg2DGKZBoaq2ELRPKH9kkmp3UTLmLht0qOjuJWkl2ZSfGXYybDQjaNYqKVBqKDSVme9IDSJQUAYK01tIiwy6hxZ6ZZ/+4t2fu3D7n3nPvPefcH+f9quri9r1nur+Hgfvc7/N8v8/XESEAQHVt6vcAAAD9RSAAgIojEABAxREIAKDiCAQAUHGn9HsAnTrzzDNjy5Yt/R4GAAyVgwcPfjcippJeG7pAsGXLFi0uLvZ7GAAwVGz/Y9prpIYAoOIIBABQcQQCAKg4AgEAVByBAAAqbuhWDQFAVcwvLWvfXY/q24dX9erJCe3esVW7tk/n/nsIBAAwgOaXlrX3sw9rde2oJGn58Kr2fvZhSco9GJAaAoABtO+uR48HgXWra0e1765Hc/9dBAIAGDDzS8taPrya+Nq3U57vRaGBwPaTth+2fcj2hu3Att9g+/n664ds31DkeABg0K2nhNJssjW/tJzr7yyjRnBpRHy3xev/KyLeUsI4AGDgJaWEGh2NyL1WQGoIAAZIltRP3rWCogNBSPqK7YO2r0+55udsP2j7S7bPS7rA9vW2F20vrqysFDdaAOjC/NKyZucWdO6eOzU7t9BT6ubVkxOZrsuzVlB0IPj5iLhQ0pslvc/265te/1tJr4mI8yX9saT5pB8SEfsjYiYiZqamEruoAkBfrOf0lw+vKnRimWe3wWD3jq2aGB9re13WgJFFoYEgIpbr/3xG0uckXdz0+v+NiBfqj78oadz2mUWOCQDylPcyz13bp3XT1ds0PTkhSzpj87jGN/mkaybGx7R7x9Zuh7xBYcVi2y+XtCki/l/98eWSbmy65p9J+j8REbYvVi0wPVvUmAAgb2kpml5SN7u2T59UCC56h3GRq4Z+VNLnbK//nr+IiC/bfrckRcTNkt4m6T22j0halfSOiIgCxwQAuXr15ETimv88UzfNgSFvhQWCiHhc0vkJz9/c8PhPJP1JUWMAgKLt3rH1pFYQUnrqpqzeQZ2i1xAA9GD9jbzdG3yW3kH9ChQEAgDoUZbUTaui8q7t06U2mWvGhjIAKEG7onKZTeaaEQgAoARpxeP154tYfZQVgQAASpC0UWy9qDy/tKxNduKfy3P1URpqBABQgrSisiTt/ezDOpqwcj7vjWNpCAQAUJKkovLs3EJit9ExWzddva2UVUOkhgCgj9JqAMciSttjwIwAALqQ15r/MnYmt8OMAAA6lGfH0VZF5LIQCACgQ3mu+d+1fVrXXDStsfqqoTFb11xUbG+hZgQCAOhQnmv+55eWdcfB5eOrho5G6I6Dy7mfS9wKgQAAOtRuc1gn+rmjeB2BAAA6lGdev587itcRCACgQ82niE1PTnS95j/P2UW3WD4KAAnaLQ9NOkVsdm6h4+WknZxnUBQCAQA06bQldC8tpLOeZ1AkD9vJkDMzM7G4uNjvYQAYYbNzC4mbvKYnJ3T/nssyX7/+ZwbhJDLbByNiJuk1agQA0KTTAm6rwm4vm83KQiAAgCadFnDbFXbLXg7aKQIBADTpdHlo0vXNylwO2imKxQCGQpkHu7cq4LYax767Hk2tFZS5HLRTBAIAA68fB7snnR3QbhxJh9BL5S8H7RSpIQADbxDaMGQdR56bzcrCjADAwCu7DUNa+ifrOJJmE4OMQABg4GU9vCWPOkKr9M8gHCJTBFJDAAZellU8eR0W0yr9MwiHyBSBQABg4GXJu+dVR2iV/hnG/H8WpIYADIV2efe86gjt0j/Dlv/PghkBgJGQVzvnUU3/tFJoILD9pO2HbR+yvaFTnGv+yPZjth+yfWGR4wEwuvJ6Ax/V9E8rZaSGLo2I76a89mZJr61//aykj9f/CQAdybOd8yimf1rpd43grZI+FbVe2A/YnrR9VkR8p8/jAjCEqvYGnpeiawQh6Su2D9q+PuH1aUnfavj+6fpzJ7F9ve1F24srKysFDRUAqqnoQPDzEXGhaimg99l+fTc/JCL2R8RMRMxMTU3lO0IAqLhCU0MRsVz/5zO2PyfpYkn3NVyyLOmchu/Prj8HYMSU2T0UnSlsRmD75bZfsf5Y0uWSvt502QFJv1JfPXSJpOepDwCjJ69dvyhGkamhH5X017YflPQ3ku6MiC/bfrftd9ev+aKkxyU9JulPJb23wPEA6JNB6R6KZIWlhiLicUnnJzx/c8PjkPS+osYAYDCU3T0Unen38lEAFZBX107qDMWgxQSAwuWx65c6Q3EIBAAKl0fbBuoMxSE1BCCTXtMyzS0g1t/As/4M6gzFIRAAaKuXw+PXA8jy4VVZtXYDnf4MaXRPBxsEpIYAtNVtWubfzT+s99966PgbeDS93klqp4rtocvCjABAW92kZeaXlvU/Hnhqw5t/Jz+jUZ7dRXEyAgGAtrpJy+y769G2QaDdz2hGd9FikBoC0FY3aZksn/RJ7QwGZgQA2uomLZM2i1g3TWpnYBAIAGTSaVpm946tJ600kiRL+leX/Jj+465tBYwQ3SIQACgExd3hQSAAUBiKu8OBYjEAVBwzAmBE0JkT3SIQACOglxYQjT+DQFJNpIaAEdBrZ05aPFcbgQAYAb125qTFc7URCIARkNamoV37hvmlZc3OLaRu/KLFczUQCIABtP4Gfe6eOzU7t9A2RdNNC4jGdFAaWjxXA4EAGDDd5Ou7OQEsKR3UyPXfnSUQYbixaggYMK3y9a3e2DvdvNUq7dPLATIYPswIgAFT1pGMaWmfMbunA2QwfJgRAAOmyCMZG/cKnD4xrvExa+3oibf9ifGx1HQRhePRxYwAGDCdFn6zFpabaw+HV9ekkM7YPH5SXWG6yxVIGF7MCIAB00nXziw7ihsPj2+2diy0+WWnaOmGy096vrl9NAfIjDYCATCAshZ+2xWWmwNFkuaUD+2jq4dAAAyJpF5A7QrL7ZaISskpH9pHVwuBAChJL03d0lJAk5vH9dyLaxuuX39zb1fgJeUDiWIxUIpem7qlpYAi1LKw3KrAOzkx3nbTGaqh8EBge8z2ku0vJLx2ne0V24fqX79W9HiAfui1qVvaJ/vDq2taXTuqTT7x3KmnnPjfeveOrXLCn5Okl596CkEAksqZEfyWpG+0eP3WiLig/vWJEsYDlK7XTWLtlm4ea9gBdnh17fhsY9f26Q2bwzr93Rh9hQYC22dLukoSb/CotG67g65L2lvQSuNsg30BaKfoGcHHJP2upGMtrrnG9kO2b7d9TtIFtq+3vWh7cWVlpZCBAkXqpjtoo+amclmsf+Lv9Xdj9BUWCGy/RdIzEXGwxWWfl7QlIn5G0t2Sbkm6KCL2R8RMRMxMTU0VMFqgeKeNn/jfrZtC7a7t07p/z2V6Yu6q1E/5jdY/8XfTmRTVUuTy0VlJO21fKek0Sa+0/emIeOf6BRHxbMP1n5D0nwocD9AXSZu6XjrSapLc3u4dW1tuFGv+xM++ALRS2IwgIvZGxNkRsUXSOyQtNAYBSbJ9VsO3O9W6qAwMpSKOgWz+lH/G5nFNTozziR9dKX1Dme0bJS1GxAFJv2l7p6Qjkr4n6bqyxwMUoXHzWFGrdviUj7yUEggi4l5J99Yf39Dw/F5Je8sYA1CWLP19pNardnrZhQx0ihYTQM6y9Pdp11Z69+0PHj8nYPnwqnbf/qCkjR1FCRTIA4EAyFm7IyDbvXH/3ucfOemwGElaOxr6wG2H9P5bD2ly87he+P4RrR07ESg4ShK9IBAAOUs7YWx6ckL377ms7Z9PaiInndg9nPR6ljONgTQ0nQNy1q8NXLSMQLeYEQA56/Vgl8mJ8doxkh2iZQS6RSAACtDL0s4P7zxPH7jt0EmN5NqhZQR6QSAABtCYrWPROhKs9xxi1RB6RSAABsy+ux49viIozfgma9+15/Pmj1wQCIAB0+vyU6BTqYHA9hclvTcinixvOMDwymuTV6/LT4FOtVo++t8kfcX2B22PlzUgYBj1eiZxI84PQNlSZwQR8RnbX5L07yUt2v5zNRwwExEfKWF8wFBo1WG001lBr8tPgU61qxH8QNI/STpV0ivU+qQxoLJ6PZO4GZ1FUaZWNYIrJH1E0gFJF0bEi6WNCujAIDRgS8vrs8kLw6DVjOCDkq6NiEfKGgzQqeaWz2U3YFsPQsuHV2XppLMHyOtjWKQWiyPiXxAEMOiKOP0rq8YCsVQLAuubvDglDMOEfQQYannn5jvx4QOPbAhCIZZ5YvjQfRRDLS0HX3Rufn5pObUxHF1AMWwIBBhqWdfczy8ta3ZuQefuuVOzcwtdre9v1Cr1RIEYw4bUEIZaljX3eReU55eWE1cIrUsKQv1e1QS0QiDA0Gu35j7PzV7rQSXNGZvHCw1CQBFIDWHk5VlQbnUw/cT4mD70i+e1vb6sVU1AVgQCjLw8C8qtgkfSctF+rmoCsiIQYOTl2cQtLXhMT04kpnr6taoJ6ASBACNv1/Zp3XT1Nk1PTsjqbbNXp0GFTqIYBhSLUQl5NXHrtDMonUQxDBxtzkUdNDMzM7G4uNjvYQDAULF9MCJmkl4jNQQAFUcgAICKIxAAQMUVXiy2PSZpUdJyRLyl6bVTJX1K0kWSnpX09oh4sugxYbTQwgHoTRkzgt+S9I2U194l6bmI+HFJH5X0+yWMByMkz0PjgaoqNBDYPlvSVZI+kXLJWyXdUn98u6Q32nbKtRhRvXQGpYUD0LuiZwQfk/S7Sj/0flrStyQpIo5Iel7Sq5ovsn297UXbiysrK0WNFX3Q6yd6WjgAvSssENh+i6RnIuJgrz8rIvZHxExEzExNTeUwOgyKXj/Rnz4x3tHzADYqslg8K2mn7SslnSbplbY/HRHvbLhmWdI5kp62fYqk01UrGqMiev1En5ZItCkiA1kVFggiYq+kvZJk+w2S/m1TEJCkA5J+VdJXJb1N0kIM21Zn9OTVkxOJh7wkNWVLemM//GLycZHPvbim37710PHvOQcASFf6PgLbN9reWf/2zyS9yvZjkj4gaU/Z40F/dXLUZFItYXJz9hQQRWQgWSlN5yLiXkn31h/f0PD89yVdW8YYMJiyNmVLqyWcesomTYyPpR4W04wiMrAR3UfRd1k6g6a9gT+/uqaPvv2C44GkXV6RcwCAjQgEGAqtagmNgWR2biH1YHnOAQCS0WsIQyFrLSHpOql2qHy3h9EAo44ZAYZC1loCB8EAneNgGgCoAA6mAQCkIjWE0rDTFxhMBAKUYn1D2Pp6f3b6AoODQIBCNH/6/6eXjqQ2lyMQAP1FIEDukj79p2GnL9B/FIuRu6R2EGnY6Qv0HzMC5C7rp/zGDWEUkoH+YUaA3KV9yj9j87imJydkSdOTE8d3+nLuMNBfzAiQu907tp5UI5Bqn/4/9IvnJX7Kb3VKGbMCoHgEArTUTcqm0zYPnDsM9BeBAKl6WfufpbX0uk5OKQOQP2oESNXrwfJZZe0sCqAYzAiQqqyUDR1Dgf4iECBVmSmbTlJJAPJFagipSNkA1cCMAKlI2QDVQCBAyyWipGyA0UcgqDjaQwOgRlBxaUtEf+e2B3Xunjs1O7dAqwdgxDEjqLi0paBH62dZM0MARh8zgorLshS0iE1kAAYHgaDikpaIJqHvDzC6SA1VUPMqoWsumtY931zRtw+vapN9PC3UiL4/wOhiRlAxSb3/7zi4rN07tuqJuav0h790/oYZgiVd+pNTfRkvgOIRCEbI/NKyZucWWq72addIbtf2aV1z0bTc8HpIuuPgMquHgBFVWCCwfZrtv7H9oO1HbP9ewjXX2V6xfaj+9WtFjWfUZT3lKy3Xv3x49Xgg+fQDT6k5OUTBGBhdRdYIXpJ0WUS8YHtc0l/b/lJEPNB03a0R8RsFjqMSWu0HkE4s/UxrJCdJuz/zoNaObawPrKNgDIymwmYEUfNC/dvx+lf6uwx60mo/QOPMYPeOrSelfRq1CgISBWNgVBVaI7A9ZvuQpGck3R0RX0u47BrbD9m+3fY5KT/netuLthdXVlaKHPLQavUm3VwD6CYa03UUGF2FBoKIOBoRF0g6W9LFtl/XdMnnJW2JiJ+RdLekW1J+zv6ImImImakpVq+saywOv/iDIxrflPZZ/+QZw3SHn+ynJyd009Xb2FkMjKhSVg1FxGFJ90i6oun5ZyPipfq3n5B0URnjGQXNxeHnXlyTLDklFjTOGJI2kY2PeUMgmRgf08fefoHu33MZQQAYYUWuGpqyPVl/PCHpTZK+2XTNWQ3f7pT0jaLGM2qSisNrR0Onnzbe9jCZXdunddPV2zQ9OSGr9ol/39vO175rzz/pOWYBQDUUuWroLEm32B5TLeDcFhFfsH2jpMWIOCDpN23vlHRE0vckXVfgeEZKWnH48Oqaztg8fjxITE6M68M7z9vwhp52zgBv/ED1FBYIIuIhSdsTnr+h4fFeSXuLGsMoS1sGatXTRHUvHTlW4qgADCN2Fg+ppDy/tXF9LhvBALRD07mCtDr+MQ9J5wmnbRRjIxiAVggEBch6/GOvwaI5zz87t5AYDNgIBqAVUkMFaNfYTcreG6gTSekiNoIBaIdAUIC0VEzj81mCRaeSloWyBBRAO6SGCpCWr29M0WQJFt1IWxYKAGmYERQgS4omLW9PPh9A2QgEynagSyeypGjI5wMYFJVPDWVZ4dPN6p52KZqk5Z+drBoqenkqgOpwJBxUPshmZmZicXExt5+XtuRyenJC9++5bEOgkGqf3PtZhB3EMQEYbLYPRsRM0muVTw21K9oWsbqnV4M4JgDDq/KBoF3RtqjVPb0YxDEBGF6VqxE059Yv/ckp3XFweUOaZb1om2UpaNbflVcev5cxAUCzSs0Iknbz3nFwWddcNJ26wqfb1T1F7Bxex4ojAHmq1IwgLbd+zzdXdP+eyxL/TLere1rl8XudFfS64ggAGlUqEHSbW+9mt27ReXx2EAPIS6VSQ2Xu5mXnMIBhUalAUGZunTw+gGFRqdRQmbl18vgAhkXldxavo2UDgFHWamdxpWYEabKeKAYAo6hSNYI0tGwAUGUEAtGyAUC1VTY11FgT2GTraEKthKWeAKqgkoGguSaQFARY6gmgKioZCJJqApI0ZutYBKuGAFRKJQNBWu7/WISemLuq5NEAQH9VslhM+wcAOKGSgYD2DwBwQiUCwfzSsmbnFnTunjs1O7cgSbrp6m2pZxAAQJUUViOwfZqk+ySdWv89t0fEh5quOVXSpyRdJOlZSW+PiCfzHEfaruGbrt6WegYBAFRJkTOClyRdFhHnS7pA0hW2L2m65l2SnouIH5f0UUm/n/cg2DUMAK0VFgii5oX6t+P1r+YF+2+VdEv98e2S3mjbeY6DXcMA0FqhNQLbY7YPSXpG0t0R8bWmS6YlfUuSIuKIpOclvSrh51xve9H24srKSkdjYIUQALRWaCCIiKMRcYGksyVdbPt1Xf6c/RExExEzU1NTHf1ZVggBQGulrBqKiMOS7pF0RdNLy5LOkSTbp0g6XbWicW52bZ9mhRAAtFDkqqEpSWsRcdj2hKQ3aWMx+ICkX5X0VUlvk7QQBZyUw0HvAJCuyBYTZ0m6xfaYajOP2yLiC7ZvlLQYEQck/ZmkP7f9mKTvSXpHgeMBACQoLBBExEOStic8f0PD4+9LuraoMQAA2qvEzmIAQDoCAQBUHIEAACrOBSzSKZTtFUn/mPLymZK+W+JwBgn3Xl1Vvn/uPbvXRETiRqyhCwSt2F6MiJl+j6MfuPdq3rtU7fvn3vO5d1JDAFBxBAIAqLhRCwT7+z2APuLeq6vK98+952CkagQAgM6N2owAANAhAgEAVNzQBQLbV9h+1PZjtvckvH6q7Vvrr3/N9pbyR1mcDPf/Adt/Z/sh239l+zX9GGcR2t17w3XX2A7bI7OsMMu92/6l+t/9I7b/ouwxFinDf/c/Zvse20v1//av7Mc482b7k7afsf31lNdt+4/q/14esn1hV78oIobmS9KYpH+Q9M8lvUzSg5J+uuma90q6uf74HZJu7fe4S77/SyVtrj9+z6jcf5Z7r1/3Ckn3SXpA0ky/x13i3/trJS1JOqP+/Y/0e9wl3/9+Se+pP/5pSU/2e9w53fvrJV0o6espr18p6UuSLOkSSV/r5vcM24zgYkmPRcTjEfEDSX+p2rnHjQo/B7mP2t5/RNwTES/Wv31AtdPhRkGWv3tJ+g+qnXvx/TIHV7As9/7rkv5zRDwnSRHxTMljLFKW+w9Jr6w/Pl3St0scX2Ei4j7VWvSneaukT0XNA5ImbZ/V6e8ZtkBw/IzjuqfrzyVeEy3OQR5SWe6/0btU+7QwCtree31afE5E3FnmwEqQ5e/9JyT9hO37bT9gu/k0wGGW5f4/LOmdtp+W9EVJ/6acofVdp+8JiYo8mAZ9ZPudkmYk/ct+j6UMtjdJ+oik6/o8lH45RbX00BtUmwXeZ3tb1I6JrYJflvTfI+IPbf+cagdevS4ijvV7YMNg2GYEx884rju7/lziNUWdg9xHWe5ftn9B0gcl7YyIl0oaW9Ha3fsrJL1O0r22n1QtX3pgRArGWf7en5Z0ICLWIuIJSX+vWmAYBVnu/12SbpOkiPiqpNNUa8o26jK9J7QzbIHgf0t6re1zbb9MtWLwgaZr1s9Blgo8B7lP2t6/7e2S/qtqQWCU8sQt7z0ino+IMyNiS0RsUa0+sjMiFvsz3Fxl+e9+XrXZgGyfqVqq6PEyB1mgLPf/lKQ3SpLtn1ItEKyUOsr+OCDpV+qrhy6R9HxEfKfTHzJUqaGIOGL7NyTdpdpKgk9GxCNVOQc54/3vk/RDkj5Tr5E/FRE7+zbonGS895GU8d7vknS57b+TdFTS7ogYiZlwxvv/HUl/avv9qhWOrxuFD4C2/6dqAf7Mev3jQ5LGJSkiblatHnKlpMckvSjpX3f1e0bg3xUAoAfDlhoCAOSMQAAAFUcgAICKIxAAQMURCACg4ggEQA9sn2P7Cds/XP/+jPr3W/o7MiA7AgHQg4j4lqSPS5qrPzUnaX9EPNm3QQEdYh8B0CPb45IOSvqkal1AL4iItf6OCshuqHYWA4MoItZs75b0ZUmXEwQwbEgNAfl4s6TvqNb4DhgqBAKgR7YvkPQm1Tqevr+bg0GAfiIQAD2on373cUm/HRFPqdb07w/6OyqgMwQCoDe/rlqH17vr3/8XST9luxIHAmE0sGoIACqOGQEAVByBAAAqjkAAABVHIACAiiMQAEDFEQgAoOIIBABQcf8f4X6b7mw5MAYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTVz4pV6XjXm"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "Gradient descent consist of 3 basic steps : \n",
        "\n",
        "1. **Compute the Loss**\n",
        "\n",
        "$$ \\hat{y} = a + bx + \\epsilon $$\n",
        "\n",
        "$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)^2 $$\n",
        "\n",
        "$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - a - bx_i)^2 $$\n",
        "\n",
        "2. **Compute the Gradients** : A gradient is a partial derivative. Using the chain rule the final expression came to be : \n",
        "\n",
        "$$\\frac{\\partial \\text{MSE}}{\\partial a} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial a} = -2 * \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)$$\n",
        "\n",
        "$$\\frac{\\partial \\text{MSE}}{\\partial b} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial b} = -2 * \\frac{1}{N} \\sum_{i} x_i(y_i - \\hat{y}_i)$$\n",
        "\n",
        "3. **Update the Parameters**\n",
        "\n",
        "$$a = a - \\alpha \\frac{\\partial \\text{MSE}}{\\partial a}$$\n",
        "\n",
        "$$b = b - \\alpha \\frac{\\partial \\text{MSE}}{\\partial b}$$\n",
        "\n",
        "4. Repeat step 1 to 3 till convergence is reached"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2EX120SXSid",
        "outputId": "5f38b564-1e62-4b81-acd8-635bad9c0547"
      },
      "source": [
        "# Initializes parameters \"a\" and \"b\" randomly\n",
        "\n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "\n",
        "print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n",
        "\n",
        "learning_rate = 1e-1 #learning rate\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  # Step 1: Computes y hat\n",
        "  yhat = a + b * x_train\n",
        "  \n",
        "  # Compute error and Loss using MSE \n",
        "  error = (y_train - yhat)\n",
        "  loss = (error ** 2).mean()\n",
        "  \n",
        "  # Step 2: Compute gradients for both \"a\" and \"b\" parameters (partial derivatives)\n",
        "  a_grad = -2 * error.mean()\n",
        "  b_grad = -2 * (x_train * error).mean()\n",
        "  \n",
        "  # Step 3: Update parameters using gradients and the learning rate\n",
        "  a = a - learning_rate * a_grad\n",
        "  b = b - learning_rate * b_grad\n",
        "    \n",
        "print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial values of [a, b] : [-1.389528167189103, 1.2528595392468875]\n",
            "Final values of [a, b] : [2.9818223574919154, 2.506904792435268]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmQcACIPeueG"
      },
      "source": [
        "## <center> PyTorch Basics<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIBkMQyGB7O6"
      },
      "source": [
        "### Tensors \n",
        "\n",
        "* How to create a Tensor\n",
        "* Operations on tensors\n",
        "* Data types for Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9BiWttzCLJs"
      },
      "source": [
        "### Create a Tensor \n",
        "\n",
        "1. Create tensors from Numpy then see what operations can be applied.\n",
        "**Note:** By default a tensor resides in cpu but can be sent to the GPU for fatser computations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKdsfJNGc86F",
        "outputId": "b28434c0-32ce-4b93-a652-c792a873cb46"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "a = torch.randn(1)\n",
        "b = torch.randn(1)\n",
        "\n",
        "print(a, b)\n",
        "print(type(a), type(b))\n",
        "print(a.type(), b.type())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0104]) tensor([-0.4392])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.FloatTensor torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64RQfhnKR1uh"
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1BpghiKSUpN",
        "outputId": "6ebeecc7-10b1-4247-9581-5e7fa47cbadb"
      },
      "source": [
        "a.requires_grad_()\n",
        "b.requires_grad_()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4392], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ct-ufpYSP2D",
        "outputId": "612890c9-b0a2-450c-aad0-ebf3680dc455"
      },
      "source": [
        "print(type(a), type(b))\n",
        "print(a.type(), b.type())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.cuda.FloatTensor torch.cuda.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oijONkV8S0XC",
        "outputId": "5105c369-7b8c-4c3c-9c87-45fc30dca845"
      },
      "source": [
        "a = torch.randn(1)\n",
        "b = torch.randn(1)\n",
        "a.requires_grad_()\n",
        "b.requires_grad_()\n",
        "a = a.to(device)\n",
        "b = b.to(device)\n",
        "print(a, b)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.3340], device='cuda:0', grad_fn=<CopyBackwards>) tensor([0.1218], device='cuda:0', grad_fn=<CopyBackwards>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC4SqM24TUHN",
        "outputId": "a5bfd1a2-90f8-4057-bb19-1124d5582997"
      },
      "source": [
        "a = torch.randn(1, device=device, requires_grad=True)\n",
        "b = torch.randn(1, device=device, requires_grad=True)\n",
        "print(a, b)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.4730], device='cuda:0', requires_grad=True) tensor([0.9873], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09aGoL3T2ld",
        "outputId": "971a4cf4-b193-4636-9993-7181a527565b"
      },
      "source": [
        "x_train_tensor = torch.from_numpy(x_train).to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([a,b], learning_rate)\n",
        "\n",
        "for epoch in range(2):\n",
        "  \n",
        "  yhat = a+b*x_train_tensor\n",
        "\n",
        "  error = (y_train_tensor - yhat)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  loss = criterion(y_train_tensor, yhat)\n",
        "\n",
        "  print(loss.item())\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  #with torch.no_grad():\n",
        "  # Step 3: Update parameters using gradients and the learning rate\n",
        "    #a -= learning_rate * a.grad\n",
        "    #b -= learning_rate * b.grad\n",
        "    #a.grad.zero_()    \n",
        "    #b.grad.zero_() \n",
        "  print(a, b)\n",
        "   "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.276078850770325\n",
            "tensor([0.3777], device='cuda:0', requires_grad=True) tensor([1.4574], device='cuda:0', requires_grad=True)\n",
            "10.051153229358796\n",
            "tensor([1.0088], device='cuda:0', requires_grad=True) tensor([1.8049], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3HKuFaVbk4",
        "outputId": "c080576b-ed8e-42f5-9d0c-7696815cb904"
      },
      "source": [
        "model = torch.nn.Sequential(torch.nn.Linear(1,1)).float().to(device)\n",
        "\n",
        "print(model.state_dict())\n",
        "model.parameters"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.8852]], device='cuda:0')), ('0.bias', tensor([0.8221], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucHOr7NLekCY"
      },
      "source": [
        "x_train_tensor = x_train_tensor.to(torch.float32)\n",
        "y_train_tensor = y_train_tensor.to(torch.float32)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Tpz7PCc6QY",
        "outputId": "7c183b96-b58b-4d27-b468-fba9b6e7aa68"
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(2):\n",
        "  \n",
        "  yhat = model(x_train_tensor)\n",
        "\n",
        "  #error = (y_train_tensor - yhat)\n",
        "  #loss = (error ** 2).mean()\n",
        "\n",
        "  loss = criterion(y_train_tensor, yhat)\n",
        "\n",
        "  print(loss.item())\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  #with torch.no_grad():\n",
        "  # Step 3: Update parameters using gradients and the learning rate\n",
        "    #a -= learning_rate * a.grad\n",
        "    #b -= learning_rate * b.grad\n",
        "    #a.grad.zero_()    \n",
        "    #b.grad.zero_() "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.423391342163086\n",
            "9.120979309082031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxhYLd2dMd15"
      },
      "source": [
        "### Dynamic Computation Graph\n",
        "\n",
        "* Easily visualize a graph using `PyTorchViz` package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGg1luKNTGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "42eaa302-bc53-4e3e-96d6-393633140bb7"
      },
      "source": [
        "!pip install torchviz \n",
        "from torchviz import make_dot\n",
        "\n",
        "a = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "c = torch.randn(1, requires_grad=True)\n",
        "\n",
        "d = a**2 + b*c - 3\n",
        "\n",
        "make_dot(d)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.7.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f9c393771d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"347pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 347.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-322 343,-322 343,4 -4,4\"/>\n<!-- 140308942407632 -->\n<g id=\"node1\" class=\"node\">\n<title>140308942407632</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"136.5,-31 82.5,-31 82.5,0 136.5,0 136.5,-31\"/>\n<text text-anchor=\"middle\" x=\"109.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140308960614416 -->\n<g id=\"node2\" class=\"node\">\n<title>140308960614416</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"154,-86 65,-86 65,-67 154,-67 154,-86\"/>\n<text text-anchor=\"middle\" x=\"109.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140308960614416&#45;&gt;140308942407632 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140308960614416&#45;&gt;140308942407632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M109.5,-66.9688C109.5,-60.1289 109.5,-50.5621 109.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0001,-41.3678 109.5,-31.3678 106.0001,-41.3678 113.0001,-41.3678\"/>\n</g>\n<!-- 140308951374224 -->\n<g id=\"node3\" class=\"node\">\n<title>140308951374224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"154,-141 65,-141 65,-122 154,-122 154,-141\"/>\n<text text-anchor=\"middle\" x=\"109.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140308951374224&#45;&gt;140308960614416 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140308951374224&#45;&gt;140308960614416</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M109.5,-121.9197C109.5,-114.9083 109.5,-105.1442 109.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0001,-96.3408 109.5,-86.3408 106.0001,-96.3409 113.0001,-96.3408\"/>\n</g>\n<!-- 140308942466832 -->\n<g id=\"node4\" class=\"node\">\n<title>140308942466832</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-196 12,-196 12,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 140308942466832&#45;&gt;140308951374224 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140308942466832&#45;&gt;140308951374224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M65.7319,-176.9197C73.2391,-169.1293 84.021,-157.9405 93.0049,-148.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.5983,-150.9703 100.017,-141.3408 90.5578,-146.113 95.5983,-150.9703\"/>\n</g>\n<!-- 140308942463184 -->\n<g id=\"node5\" class=\"node\">\n<title>140308942463184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140308942463184&#45;&gt;140308942466832 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140308942463184&#45;&gt;140308942466832</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M51.5451,-231.9197C52.31,-224.9083 53.3752,-215.1442 54.322,-206.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.8213,-206.6614 55.4265,-196.3408 50.8625,-205.9023 57.8213,-206.6614\"/>\n</g>\n<!-- 140308942356560 -->\n<g id=\"node6\" class=\"node\">\n<title>140308942356560</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-318 23.5,-318 23.5,-287 77.5,-287 77.5,-318\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140308942356560&#45;&gt;140308942463184 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140308942356560&#45;&gt;140308942463184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-286.791C50.5,-279.0249 50.5,-269.5706 50.5,-261.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-261.0647 50.5,-251.0648 47.0001,-261.0648 54.0001,-261.0647\"/>\n</g>\n<!-- 140308942463696 -->\n<g id=\"node7\" class=\"node\">\n<title>140308942463696</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-196 125,-196 125,-177 214,-177 214,-196\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140308942463696&#45;&gt;140308951374224 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140308942463696&#45;&gt;140308951374224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159.0488,-176.9197C150.4651,-169.0514 138.0997,-157.7164 127.8693,-148.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"129.9721,-145.5181 120.2355,-141.3408 125.242,-150.6782 129.9721,-145.5181\"/>\n</g>\n<!-- 140308942463568 -->\n<g id=\"node8\" class=\"node\">\n<title>140308942463568</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"220,-251 119,-251 119,-232 220,-232 220,-251\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140308942463568&#45;&gt;140308942463696 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140308942463568&#45;&gt;140308942463696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.5,-231.9197C169.5,-224.9083 169.5,-215.1442 169.5,-206.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.0001,-206.3408 169.5,-196.3408 166.0001,-206.3409 173.0001,-206.3408\"/>\n</g>\n<!-- 140308942332624 -->\n<g id=\"node9\" class=\"node\">\n<title>140308942332624</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"196.5,-318 142.5,-318 142.5,-287 196.5,-287 196.5,-318\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140308942332624&#45;&gt;140308942463568 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140308942332624&#45;&gt;140308942463568</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.5,-286.791C169.5,-279.0249 169.5,-269.5706 169.5,-261.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.0001,-261.0647 169.5,-251.0648 166.0001,-261.0648 173.0001,-261.0647\"/>\n</g>\n<!-- 140308942464144 -->\n<g id=\"node10\" class=\"node\">\n<title>140308942464144</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"339,-251 238,-251 238,-232 339,-232 339,-251\"/>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140308942464144&#45;&gt;140308942463696 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140308942464144&#45;&gt;140308942463696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M267.7718,-231.9197C248.9465,-223.219 220.9495,-210.2792 199.6487,-200.4343\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.9357,-197.1734 190.39,-196.155 197.9989,-203.5276 200.9357,-197.1734\"/>\n</g>\n<!-- 140310526697632 -->\n<g id=\"node11\" class=\"node\">\n<title>140310526697632</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"315.5,-318 261.5,-318 261.5,-287 315.5,-287 315.5,-318\"/>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140310526697632&#45;&gt;140308942464144 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140310526697632&#45;&gt;140308942464144</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M288.5,-286.791C288.5,-279.0249 288.5,-269.5706 288.5,-261.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.0001,-261.0647 288.5,-251.0648 285.0001,-261.0648 292.0001,-261.0647\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9vbK5KLgmOH"
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKfAGnuig8nE",
        "outputId": "2b0983f0-398c-40ad-b5fc-b97ccc0461c0"
      },
      "source": [
        "test_model = torch.nn.Sequential(torch.nn.Linear(1,1))\n",
        "test_model.state_dict()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[0.2223]])), ('0.bias', tensor([-0.5164]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azquLXgUhLxq",
        "outputId": "9e4656e9-efae-478b-e5ba-07b189f2a073"
      },
      "source": [
        "test_model.load_state_dict(torch.load(\"model.pt\"))\n",
        "test_model.state_dict()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[-0.0693]])), ('0.bias', tensor([2.1924]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nImWn-F7Q72D"
      },
      "source": [
        "### Autograd & Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c2pYDGNRDaS"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYSyCi_9RI8D"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWjqs5tLRPZw"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwi1O6ORQRN"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGcFMG-NRbZ8"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    }
  ]
}